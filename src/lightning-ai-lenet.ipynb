{
 "cells": [
  {
   "cell_type": "code",
   "id": "41cd16251b6448b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-22T18:57:48.629731Z",
     "start_time": "2024-10-22T18:57:46.923847Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchmetrics\n",
    "import torchvision as tv\n",
    "\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Identical code as file `lightning-ai-demo-cpu.ipynb`. The only difference is the output. I'm running this Jupyter notebook on my Macbook Pro M2 with built-in GPU. Lightning (formerly named pytorch-lightning) will detect the GPU and use it if possible.\n",
    "\n",
    "print(\"Using torch\", torch.__version__)\n",
    "print(\"Using lightning\", L.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 2.5.0\n",
      "Using lightning 2.4.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "5748d0b5a58da137",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-22T18:57:51.461324Z",
     "start_time": "2024-10-22T18:57:51.352987Z"
    }
   },
   "source": [
    "# --------------------\n",
    "# Load Dataset - MNIST\n",
    "# --------------------\n",
    "\n",
    "# dataset: tuple[tensor of shape (N, R, C), label: int]\n",
    "dataset = tv.datasets.MNIST(root=\".\", download=True, transform=tv.transforms.ToTensor())\n",
    "train, val, test = data.random_split(dataset, [55000, 4000, 1000], torch.Generator().manual_seed(42))\n",
    "\n",
    "# visualize\n",
    "n = 44\n",
    "image, label = train[n]\n",
    "print(f\"Number of training samples: {len(train)}\")\n",
    "print(f\"Number of validation samples: {len(val)}\")\n",
    "print(f\"Number of test samples: {len(test)}\")\n",
    "print(f\"Shape of image: {image.shape}\")\n",
    "print(f\"Label for this image: {label}\")\n",
    "plt.imshow(image.squeeze(), cmap=\"gray\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 55000\n",
      "Number of validation samples: 4000\n",
      "Number of test samples: 1000\n",
      "Shape of image: torch.Size([1, 28, 28])\n",
      "Label for this image: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16a959750>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "fffcc4804b777f3d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-22T18:57:52.447818Z",
     "start_time": "2024-10-22T18:57:52.443072Z"
    }
   },
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uAeANQIOQPqWZnnuH-VEyw.jpeg\")"
   ],
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uAeANQIOQPqWZnnuH-VEyw.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "7a37f32f5ea517a9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-22T18:57:53.454360Z",
     "start_time": "2024-10-22T18:57:53.446429Z"
    }
   },
   "source": [
    "# ------------\n",
    "# Create Model\n",
    "# ------------\n",
    "class LeNetModel(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 28 x 28 x 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 28 x 28 x 6\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            # 14 x 14 x 6\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 10 x 10 x 16\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            # 5 x 5 x 16\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=5 * 5 * 16, out_features=120), \n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(in_features=120, out_features=84), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        loss = self._step(batch, step_type=\"train\")\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        loss = self._step(batch, step_type=\"val\")\n",
    "        return loss\n",
    "    \n",
    "    def _step(self, batch, step_type: str):\n",
    "        images, labels = batch  # images: NxRxC\n",
    "        \n",
    "        # make predictions\n",
    "        predictions = self.encoder(images)\n",
    "        \n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        self.log(f\"{step_type}_loss\", loss)\n",
    "        \n",
    "        if step_type == \"train\":\n",
    "            self.train_accuracy(predictions, labels)\n",
    "            self.log(f\"{step_type}_accuracy\", self.train_accuracy)\n",
    "        else:\n",
    "            self.val_accuracy(predictions, labels)\n",
    "            self.log(f\"{step_type}_accuracy\", self.val_accuracy)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "c01d4a31fbc939dd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-10-22T19:01:01.936921Z",
     "start_time": "2024-10-22T18:57:54.815556Z"
    }
   },
   "source": [
    "# -----------\n",
    "# Train Model\n",
    "# -----------\n",
    "model = LeNetModel()\n",
    "model.eval()\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    dataset=train,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "val_dataloader = data.DataLoader(\n",
    "    dataset=val,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=20,\n",
    "    enable_progress_bar=False,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type               | Params | Mode\n",
      "-------------------------------------------------------------\n",
      "0 | encoder        | Sequential         | 61.7 K | eval\n",
      "1 | train_accuracy | MulticlassAccuracy | 0      | eval\n",
      "2 | val_accuracy   | MulticlassAccuracy | 0      | eval\n",
      "-------------------------------------------------------------\n",
      "61.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "61.7 K    Total params\n",
      "0.247     Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "15        Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# -------------\n",
    "# Run Inference\n",
    "# -------------\n",
    "for n in [53, 54, 55]:\n",
    "    image, label = test[n]\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    images = torch.stack((image, image), dim=0)\n",
    "    pred = softmax(model.encoder(images)).detach().numpy().squeeze()\n",
    "    # show\n",
    "    plt.figure()\n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    print(label)\n",
    "    print([\"{0}:{1:.3%}\".format(i, prob) for i, prob in enumerate(pred[0])])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac592093577915a2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": "# tensorboard --logdir . ",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
